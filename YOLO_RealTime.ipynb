{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import imutils #for preprocessimg and resizing the image\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "DQNWDcyYOsmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import pyttsx3\n",
        "'''def tts():\n",
        "    engine = pyttsx3.init()\n",
        "    rate = engine.getProperty('rate')\n",
        "    engine.setProperty('rate', rate+0)\n",
        "    engine.say(label)\n",
        "    engine.runAndWait()'''\n",
        "# the above line is for text to speach conversion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "HpXbxzEXOxam",
        "outputId": "a09d1157-392d-462b-8321-a633ad49358e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"def tts():\\n    engine = pyttsx3.init()\\n    rate = engine.getProperty('rate')\\n    engine.setProperty('rate', rate+0)\\n    engine.say(label)\\n    engine.runAndWait()\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Yolo\n",
        "net = cv2.dnn.readNet(\"/content/drive/MyDrive/Model datasets/yolov3.weights\", \"/content/drive/MyDrive/Model datasets/yolov3.cfg\")\n",
        "classes = []\n",
        "with open(\"/content/drive/MyDrive/Model datasets/coco.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "layer_names = net.getLayerNames()\n",
        "output_layers = ([layer_names[i - 1] for i in net.getUnconnectedOutLayers()])\n",
        "colors = np.random.uniform(0, 255, size=(len(classes), 3))"
      ],
      "metadata": {
        "id": "4vsBmz58O134"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNe-0zW3DurB",
        "outputId": "f22febe8-3581-4d0b-c3d4-845f874fa57e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to grab frame. Check camera connection.\n"
          ]
        }
      ],
      "source": [
        "# Loading image\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "  i=0\n",
        "  ret,img=cap.read()\n",
        "  if not ret: # Check if a frame was successfully read\n",
        "      print(\"Failed to grab frame. Check camera connection.\")\n",
        "      break # Exit loop if no frame is captured\n",
        "\n",
        "  img = imutils.resize(img, width=600)\n",
        "    #cv2.imshow(\"resized output\",img)\n",
        "  height, width, channels = img.shape\n",
        "\n",
        "    # Detecting objects\n",
        "  blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "\n",
        "  net.setInput(blob)\n",
        "  outs = net.forward(output_layers)\n",
        "\n",
        "# Showing informations on the screen\n",
        "  class_ids = []\n",
        "  confidences = []\n",
        "  boxes = [] # Initialize boxes here\n",
        "  for out in outs:\n",
        "      for detection in out:\n",
        "          scores = detection[5:]\n",
        "          class_id = np.argmax(scores)\n",
        "          confidence = scores[class_id]\n",
        "          if confidence > 0.5:\n",
        "          # Object detected\n",
        "              center_x = int(detection[0] * width)\n",
        "              center_y = int(detection[1] * height)\n",
        "              w = int(detection[2] * width)\n",
        "              h = int(detection[3] * height)\n",
        "\n",
        "                # Rectangle coordinates\n",
        "              x = int(center_x - w / 2)\n",
        "              y = int(center_y - h / 2)\n",
        "\n",
        "              boxes.append([x, y, w, h])\n",
        "              confidences.append(float(confidence))\n",
        "              class_ids.append(class_id)\n",
        "\n",
        "  indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4) # Now boxes is defined\n",
        "  font = cv2.FONT_HERSHEY_PLAIN\n",
        "  for i in range(len(boxes)):\n",
        "    if i in indexes:\n",
        "        x, y, w, h = boxes[i]\n",
        "        label = str(classes[class_ids[i]])\n",
        "        if(classes[class_ids[i]] == classes[class_ids[i]] ):\n",
        "            i+=1\n",
        "            print(\"Number of objects:\",i)\n",
        "            color = colors[i]\n",
        "            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
        "            cv2.putText(img, label, (x, y + 30), font, 3, color, 3)\n",
        "            print(label)\n",
        "            #tts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show the output frame\n",
        "from google.colab.patches import cv2_imshow # Use cv2_imshow instead of cv2.imshow\n",
        "cv2_imshow(img) # Display the processed image using cv2.imshow"
      ],
      "metadata": {
        "id": "u2JQkaaaPDNO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}